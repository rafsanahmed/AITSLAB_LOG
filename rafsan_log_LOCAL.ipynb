{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to create a log of tasks for Rafsan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# October 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th October, 2020\n",
    "---\n",
    "### Project\n",
    "Image Blur\n",
    "\n",
    "### Aim\n",
    "Read Jon's Masters thesis and create a plan for the project. Use available resources, such as the michigan tech DL lectures on youtube.\n",
    "\n",
    "### Description\n",
    "Gained some understanding into the project. The project revolves around classification between focused vs unfocused genome wide screen. Continuing lectures.\n",
    "\n",
    "### Next Steps\n",
    "Create a classifier for blurred images using the dataset from https://bbbc.broadinstitute.org/BBBC006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6th October, 2020\n",
    "---\n",
    "### Project\n",
    "IMAGE Blur\n",
    "\n",
    "### Aim\n",
    "Start developing a model\n",
    "\n",
    "### Description\n",
    "Downloaded images from broad institute. Inspected them. Looked particularly on the planes 15,16 and 17 for focused images and 0,1 and 31 for unfocused images. Considering such planes are expected to give a proper classification among focused and blurred images.\n",
    "\n",
    "Looked at basic CNN structures\n",
    "\n",
    "### Next Steps\n",
    "Create a classifier for blurred images using the dataset from https://bbbc.broadinstitute.org/BBBC006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13th October, 2020\n",
    "---\n",
    "### Project\n",
    "IMAGE Blur\n",
    "\n",
    "### Aim\n",
    "Finalize models\n",
    "\n",
    "### Description\n",
    "Created 3 different models. One with simple vgg block, one with three vgg blocks with dropout and on with vgg 16 transfer learning. The first ones gave 48-50% accuracy where transfer learning gave 72% accuracy\n",
    "\n",
    "### Next Steps\n",
    "Try to fine tune basee models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20th October, 2020\n",
    "---\n",
    "### Project\n",
    "IMAGE Blur\n",
    "\n",
    "### Aim\n",
    "Fine tune model\n",
    "\n",
    "### Description\n",
    "Try adam optimizer, adaptive learning rate. No improvement\n",
    "\n",
    "### Next Steps\n",
    "Try resnet and unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23th October, 2020\n",
    "---\n",
    "### Project\n",
    "NLP - pipeline\n",
    "\n",
    "### Aim\n",
    "Cover some basics about NLP\n",
    "\n",
    "### Description\n",
    "Go through terms like NER, tokenization, lemmatization etc\n",
    "\n",
    "### Next Steps\n",
    "Apply NER to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28th October, 2020\n",
    "---\n",
    "### Project\n",
    "NLP - pipeline\n",
    "\n",
    "### Aim\n",
    "Attend NLP workshop\n",
    "\n",
    "### Description\n",
    "NLP workshop given by Johan frid. Was not that useful.\n",
    "\n",
    "### Next Steps\n",
    "Apply NER to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "UNET models\n",
    "\n",
    "### Description\n",
    "Look into how unet models work.\n",
    "\n",
    "### Next Steps\n",
    "Unet on LUNARC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Malou's Unet code\n",
    "\n",
    "### Description\n",
    "Look into Malou's code and tried running. Pre-processing worked but training gave dependency issues.\n",
    "\n",
    "### Next Steps\n",
    "Fix issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Malou's Unet code on LUNARC\n",
    "\n",
    "### Description\n",
    "Get LUNARC access. Tried running scripts there but have dependency issues.\n",
    "\n",
    "### Next Steps\n",
    "Fix issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Setup kebnekaise and also use openvpn to access the server\n",
    "\n",
    "### Description\n",
    "Set up Kebnekaise using the following steps:\n",
    "\n",
    "1. Request a user account from SNIC -> HPC2N. The SNIC account was created before.\n",
    "2. Using the login information sent by Kebnekaise personnel (took 2 days), open kebnekaise server using SSH. Since I am using windows, putty was used to run terminal commands. A detailed description is provided in: https://www.hpc2n.umu.se/quickstart\n",
    "3. Once gained access, change the password.\n",
    "4. Now kebnekaise is accessible either through thinLinc or SSH. The server ID is: kebnekaise.hpc2n.umu.se. Note for Lunarc it is aurora.lunarc.lu.se\n",
    "\n",
    "### Results/Conclusion\n",
    "Have access to Kebnekaise now\n",
    "\n",
    "### Next Steps\n",
    "FIX openVPN issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Work on pre-trined models on unet\n",
    "\n",
    "### Description\n",
    "Looked into inception v3 on unet. Aim to implement a simple unet model. Try running scripts on server.\n",
    "\n",
    "### Results/Conclusion\n",
    "Inception v3 appeared tricky to be run on Unet. I couldn't figure out how to use skip connections with pre-trained weights from Inception to Unet\n",
    "\n",
    "### Next Steps\n",
    "Read up on Unet and pre-trained models. Later, implement model with Malou's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 13th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Work on pre-trined models on unet\n",
    "\n",
    "### Description\n",
    "Attempted running Kaggle Carvana colab notebook with VGG16. https://colab.research.google.com/github/MarkDaoust/models/blob/segmentation_blogpost/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb\n",
    "\n",
    "### Results/Conclusion\n",
    "Similar to inception, it was unsuccessfull. The colab notebook gave several errors with the image dataset. Need to build something from scratch\n",
    "\n",
    "### Next Steps\n",
    "Continue Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Adapted Alexandro's tile script to generate 256x256 tiles as inputs for Malou's unet model.\n",
    "\n",
    "### Description\n",
    "Hardcoded the script to create 256x256 tiles. However, I detected several blank tiles when inspecting results.\n",
    "\n",
    "### Next Steps\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Summerize challenge and visualize UNET architecture\n",
    "\n",
    "### Description\n",
    "Assisted the team with several small tasks including writing a script for the visualization of the Unet architecture.\n",
    "Source:https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/\n",
    "Script location: \"shared_data/malou_model5/viz/viz.py\" on Lunarc\n",
    "\n",
    "### Results/Conclusion\n",
    "It was an interesting challenge. However, more work needs to be done to implement pre-trained models on unet.\n",
    "\n",
    "### Next Steps\n",
    "Continue with the project for implementing pre-trained model with Unet (Autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Run Antton's code for NER. Test out the following models:\n",
    "1. NER_biobert-BC5CDRChem_Antton_1, \n",
    "2. NER_biobert-JNLPBA_Antton_1, \n",
    "3. NER_biobert-NCBIdisease_Antton_1\n",
    "\n",
    "### Description\n",
    "Model files were not available. Asked Antton for the files.\n",
    "\n",
    "### Results/Conclusion\n",
    "Waiting for the files\n",
    "\n",
    "### Next Steps\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Use Antton's models to evaluate.\n",
    "\n",
    "### Description\n",
    "Files were received from Antton. His models are located at his personal drive: https://drive.google.com/drive/u/2/folders/1vXBYTh7WmJh8bpmrYTevKLgDuMXemzTZ\n",
    "\n",
    "It was understood that Antton used BIOBERT code to evaluate his models. I will attempt to use the same code for evaluation.\n",
    "\n",
    "### Results/Conclusion\n",
    "Files were shared. However, downloading from Gdrive seemed to give only 1 GB zip files at a time. \n",
    "Trying to understand the evaluation code: \"utils/pubannotationevaluator.py\"\n",
    "\n",
    "### Next Steps\n",
    "Get evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23rd November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Run Antton's Scripts and get results.\n",
    "\n",
    "### Description\n",
    "Was able to successfully run evaluation script, \"utils/use_evaluator.py\". This script is based on the original evaluation code \"utils/pubannotationevaluator.py\".\n",
    "\n",
    "### Results/Conclusions\n",
    "Running the script on \"GOLD william results\", gave a precision value of 26% and recall of 30%. I don't fully understand the script and the terms related to NLP yet.\n",
    "\n",
    "### Next Steps\n",
    "Do a literature review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Improving background in NLP\n",
    "\n",
    "### Description\n",
    "Informed sonja about being unable to understand the script. She shared the following materials to go through.\n",
    "\n",
    "1. Transformers - Attention is all you need: https://arxiv.org/pdf/1706.03762.pdf\n",
    "2. BERT : https://arxiv.org/pdf/1810.04805.pdf\n",
    "3. BioBERT: https://academic.oup.com/bioinformatics/article/36/4/1234/5566506\n",
    "4. Blog Posts: https://jalammar.github.io/illustrated-transformer/\n",
    "5. Blog Posts: http://jalammar.github.io/illustrated-bert/\n",
    "6. CS224 NLP Stanford materials: https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z\n",
    "7. Pubannotation formats: http://www.pubannotation.org/docs/annotation-format/\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "Went through the BERT papers and CS224 lectures briefly. The lectures seemed a bit difficult to understand but the papers were nice.  \n",
    "\n",
    "### Next Steps\n",
    "Continue going through the materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Check if the results in Antton's report matches mine\n",
    "\n",
    "### Description\n",
    "I am expected to run the following three models:\n",
    "1. NCBI Disease\n",
    "2. JNLPBA\n",
    "3. BC5CDR-Chem\n",
    "\n",
    "The firist two folders are located at the \"data/dataset/\" folder in Antton's repo.\n",
    "\n",
    "### Results/Conclusions\n",
    "Following the use_evaluater.py script from Antton, the precision-recall values matched table2 of Antton's preliminary report located in: https://github.com/Aitslab/BioNLP/blob/master/antton/Antton_ProjectReport.docx\n",
    "\n",
    "| Name         | Precision (%) | Recall (%) |\n",
    "|--------------|---------------|------------|\n",
    "| NCBI Disease | 31            | 35         |\n",
    "| JNLPBA       | 0             | 0          |\n",
    "\n",
    "BC5DR-CHEM was not available in the datasets.\n",
    "\n",
    "However, the results were comparable to table 2 of the report and table 1. The evaluation script seems to run on the dataset folder. The models shared by Antton also did not have the right format to run the evaluation script on.\n",
    "\n",
    "\n",
    "### Next Steps\n",
    "Need further understanding of the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Meeting and discussion about Antton's models\n",
    "\n",
    "### Description\n",
    "The models were in drive. However while downloading, the models split into multiple files. We needed to contact Antton about the files.\n",
    "\n",
    "### Results/Conclusions\n",
    "On 2nd December it was decided to individually download the files despite the split\n",
    "### Next Steps\n",
    "Continuation with the NLP course (Udemy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st and 2nd December 2020\n",
    "---\n",
    "Setting up the Laptop including Anaconda, Thinlinc and additional programs for servers and setting up CUDA. CUDA setup was not completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd December 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Download Models run by Antton. Add to Lunarc.\n",
    "\n",
    "### Description\n",
    "The models are 6-8 GB folders each. I have initially tried to download the three models described in Antton's paper.\n",
    "1. NCBI Disease\n",
    "2. JNLPBA\n",
    "3. BC5CDR-Chem\n",
    "\n",
    "### Results/Conclusions\n",
    "Number 2 and 3 has already been added to Lunarc at snic2020-6-41/rafsan/Antton models. The rest of the models follow\n",
    "\n",
    "### Next Steps\n",
    "Continuation with the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd December 2020\n",
    "---\n",
    "### Project\n",
    "Citizen Scientist game by Salma\n",
    "\n",
    "### Aim\n",
    "Run the game and annotate 100 images\n",
    "\n",
    "### Description\n",
    "The citizen scientist game developed by Salma has 4 levels with unique tasks. The idea is to annotate 100 images and do a test for the game itself to see that everything is working smoothly.\n",
    "\n",
    "The game was run by using bash and separately using Anaconda. In both instances we received multiple bugs, mostly revolving around local variables (for example \"con\" and \"P1 full filename\") referenced before assignment.\n",
    "\n",
    "### Results/Conclusions\n",
    "The game needs debugging. I am not sure if the errors occur due to LUNARC or the code itself. I have forwarded my findings to Salma.\n",
    "\n",
    "### Next Steps\n",
    "Continue with annotations after receiving the debugged game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th December 2020\n",
    "---\n",
    "### Project\n",
    "Citizen Scientist game by Salma\n",
    "\n",
    "### Aim\n",
    "Get the game running on my lunarc\n",
    "\n",
    "### Description\n",
    "Had several discussions with Salma about the bugs in the game. At first I tried to create a new environment similar to her local system. However that did not pan out. Later we discovered that, these specific errors can arise when trying to run the game from the folder \"Rafsan Game\" and not the game folder within this folder. The environment loaded but the specific file paths were one level up. I ran the game in the correct folder and it executed smoothly.\n",
    "\n",
    "### Results/Conclusions\n",
    "The game works on my lunarc now.\n",
    "\n",
    "### Next Steps\n",
    "Salma asked me to annotate 100 images for each channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7th December 2020\n",
    "---\n",
    "### Project\n",
    "Citizen Scientist game by Salma\n",
    "\n",
    "### Aim\n",
    "Annotation of 100 images for each level\n",
    "\n",
    "### Description\n",
    "Annotated images for level 1,2,3 and 4. Level 1: blur detection seemed ambiguous.\n",
    "\n",
    "### Results/Conclusions\n",
    "Annotations are done.\n",
    "\n",
    "### Next Steps\n",
    "Need to discuss the results with Salma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-11th December 2020\n",
    "---\n",
    "Continuation of the NLP course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21 December 2020 onward\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline\n",
    "\n",
    "### Aim\n",
    "Rerun the scripts from petter alexander github repo at: https://github.com/askft/thesis-code\n",
    "\n",
    "### Description\n",
    "1. Cloned the repo to local. Created the anaconda environment py37\n",
    "\n",
    "\n",
    "2. Received an error on installing requirements from the repo. Commented out the pubmed_parser line within the requirements.txt file. Installation from cmd line doesn't work. The downloader.py requires pubmed_parser. Therefore, I installed it to the conda env by directly using the command: pip install git+git://github.com/titipata/pubmed_parser.git\n",
    "\n",
    "    SKlearn is not in the requirements and not installed. This should be added to the requirements.\n",
    "\n",
    "\n",
    "3. For running the code, there are several steps. However I could reach only the following step before running into an issue:\n",
    "\n",
    "  a. For step 1 (in the repo), the main.py script needs to run. But in order to do that, the config.json file needs to be set.\n",
    "  For this step, both cord_loader and downloader in the pipeline gave an error. However, it seems that the cord loader is only lacking the metadata.csv file whereas the downloader has an unicode error. \" character '\\u03b2'\" which refers to a beta.\n",
    "  \n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "The downloader doesn't function well. Need to examine this more. \n",
    "\n",
    "### Next Steps\n",
    "Continuations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th January 2020\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline\n",
    "\n",
    "### Aim\n",
    "Rerun the scripts from petter alexander github repo at: https://github.com/askft/thesis-code\n",
    "\n",
    "### Description\n",
    "\n",
    "The cord-19 data was downloaded from the source: https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html. \n",
    "\n",
    "The file was extracted into a newly created data/cord folder. The metadata.csv file was placed in this folder. The config.json file was changed to include the cord loader instead by changing the boolean fields to true/false. Running the main.py code gave the same **\"UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 1507: character maps to undefined> \"**. It seems that this error may be caused due to encoding when loading the file. A stackoverflow search identifies the issue to be a UTF-8 encoding error. The following adjustment may be needed somewhere in the loader script:\\\n",
    "\n",
    "```\n",
    "file = open(filename, encoding=\"utf8\")\n",
    "```\n",
    "  \n",
    "I tried to make the above change to line 23 of the cord_loader script in the scipt/ folder. But that did not change the outcome.\n",
    "  \n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "Contacted Petter-Alexander on discord. Waiting for their reply.\n",
    "\n",
    "### Next Steps\n",
    "Continuation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14th January 2020\n",
    "---\n",
    "### Event\n",
    "Meeting with Sonja\n",
    "\n",
    "### Points\n",
    "1. Run petter-alexander code by implementing changes\n",
    "2. Prepare a jupyter-notebook like Antton's at https://github.com/Aitslab/BioNLP/blob/master/evaluation/antton/evaluations_table.csv\n",
    "3. Look for grants at the intramed database:  \n",
    "    a. https://www.med.lu.se/english/intramed  \n",
    "    b. https://www.med.lu.se/intramed/stipendier_anslag_fraan_fakulteten  \n",
    "    c. https://www.keystonesymposia.org/ks/online  \n",
    "    d. https://www.grc.org/  \n",
    "    e. https://www.ebi.ac.uk/  \n",
    "    f. https://meetings.cshl.edu/meetingshome.aspx  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18th January 2020\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline\n",
    "\n",
    "### Aim\n",
    "Rerun the scripts from petter alexander github repo at: https://github.com/askft/thesis-code\n",
    "\n",
    "### Description\n",
    "Salma was able to run the scripts in lunarc while I wasn't able to run on my computer. I eventually proceeded to install ubuntu for windows in my computer and run the scripts on the windows subsystems for linux. There is a nice tutorial for this at: https://www.youtube.com/watch?v=X-DHaQLrBi8  \n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "On this subsystem both downloader and cord_loader worked. However the sentencer and NER did not work. \n",
    "\n",
    "### Next Steps\n",
    "Continuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20th January 2020\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline\n",
    "\n",
    "### Aim\n",
    "Rerun the scripts from petter alexander github repo at: https://github.com/askft/thesis-code\n",
    "\n",
    "### Description\n",
    "With Salma's help, I was able to run CORD loader and get metadata.json in the same folder with metadata.csv. This works with ubuntu\n",
    "\n",
    "I proceeded with the sentencer script and that executed on ubuntu as well.  \n",
    "\n",
    "Now, the NER script did not execute since there was no BERT tokenizer. The authors did not mention this on their repo.\n",
    "\n",
    "In the repo there is a mention of  converting biobert to ONNX. But nothing specific about biobert installation etc. After downloading the model I was able to run the NER script. Although it shows that the NER is limited to 15 articles.\n",
    "\n",
    "The re script may have an incorrect path. data/cord/... instead of data/...\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "Sent petter alexander an email with my comments. \n",
    "\n",
    "### Next Steps\n",
    "Continuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th February 2020\n",
    "---\n",
    "### Meeting\n",
    "Half yearly assessment\n",
    "\n",
    "### Aim\n",
    "Review performance and plan ahead\n",
    "\n",
    "### Description\n",
    "Following issues were discussed:\n",
    "\n",
    "* Improve productivity by working in blocks and working 8 hours\n",
    "* Work fika (except mon and wed)\n",
    "* Network with people from the industry. Attent career fare from MED + SCI +  LTH and ask career people for including me in newsletter.\n",
    "* Implement Agile method in lab.\n",
    "* Do CV + NLP course on my own time\n",
    "* Improve technical skills by working\n",
    "* LINXS - events(?)\n",
    "* Log every day\n",
    "* Read 1 paper/ week\n",
    "* Pytorch for projects\n",
    "* NLP pipeline takes importance\n",
    "* Apply for 1 grant at least\n",
    "* Collaborate with Salma. I lead NLP and Salma Image processing. But we help each other out and collaborate.\n",
    "* Aim to publish 8 papers from the lab this year.\n",
    "\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "__\n",
    "\n",
    "### Next Steps\n",
    "Continuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-10th February 2020\n",
    "---\n",
    "### Project\n",
    "Transcriptomics paper\n",
    "\n",
    "### Aim\n",
    "Readings\n",
    "\n",
    "### Description\n",
    "\n",
    "### Results/Conclusions\n",
    "Had some difficulties understanding the biological parts\n",
    "\n",
    "### Next Steps\n",
    "Continuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15th February 2020\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline\n",
    "\n",
    "### Aim\n",
    "Building the pipeline\n",
    "\n",
    "### Description\n",
    "Started with the loader scripts of Petter-Alexander. Going to continue further with sentencer and NER.\n",
    "\n",
    "### Results/Conclusions\n",
    "The loader scripts run smoothly without issues on Jupyter. Need to understand how the models of Antton and Petter-Alexander compare in terms of the gold standard corpus\n",
    "\n",
    "### Next Steps\n",
    "Use the sentencer and NER and run predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16th February 2020\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline - Antton\n",
    "\n",
    "### Aim\n",
    "Meeting with Antton about BioBERT, gold standard and differences between the numbers from evaluations (precision/recall)\n",
    "\n",
    "### Description\n",
    "Following points were discussed:\n",
    "\n",
    "1. For Sofi's use evaluator script, each word class should be exclusively defined.\n",
    "2. The gold standard was manually annotated by sonja/salma\n",
    "3. The reason behind the differences in the numbers is due to running different scripts. The bioBERT native evaluator (in perl) is used for the models with good results while sofi's evaluation against the gold standard gives lower numbers. The way Antton used his results for bioBERT is that he replaced the test file with the gold standard one.\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "Antton's percentages are low. Are we going to use his models?\n",
    "\n",
    "### Next Steps\n",
    "Continue with pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16th February 2020\n",
    "---\n",
    "### Project\n",
    "NLP Pipeline\n",
    "\n",
    "### Aim\n",
    "Progress with pipeline\n",
    "\n",
    "### Description\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "__\n",
    "\n",
    "### Next Steps\n",
    "__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
