{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to create a log of tasks for Rafsan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# October 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th October, 2020\n",
    "---\n",
    "### Project\n",
    "Image Blur\n",
    "\n",
    "### Aim\n",
    "Read Jon's Masters thesis and create a plan for the project. Use available resources, such as the michigan tech DL lectures on youtube.\n",
    "\n",
    "### Description\n",
    "Gained some understanding into the project. The project revolves around classification between focused vs unfocused genome wide screen. Continuing lectures.\n",
    "\n",
    "### Next Steps\n",
    "Create a classifier for blurred images using the dataset from https://bbbc.broadinstitute.org/BBBC006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6th October, 2020\n",
    "---\n",
    "### Project\n",
    "IMAGE Blur\n",
    "\n",
    "### Aim\n",
    "Start developing a model\n",
    "\n",
    "### Description\n",
    "Downloaded images from broad institute. Inspected them. Looked particularly on the planes 15,16 and 17 for focused images and 0,1 and 31 for unfocused images. Considering such planes are expected to give a proper classification among focused and blurred images.\n",
    "\n",
    "Looked at basic CNN structures\n",
    "\n",
    "### Next Steps\n",
    "Create a classifier for blurred images using the dataset from https://bbbc.broadinstitute.org/BBBC006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13th October, 2020\n",
    "---\n",
    "### Project\n",
    "IMAGE Blur\n",
    "\n",
    "### Aim\n",
    "Finalize models\n",
    "\n",
    "### Description\n",
    "Created 3 different models. One with simple vgg block, one with three vgg blocks with dropout and on with vgg 16 transfer learning. The first ones gave 48-50% accuracy where transfer learning gave 72% accuracy\n",
    "\n",
    "### Next Steps\n",
    "Try to fine tune basee models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20th October, 2020\n",
    "---\n",
    "### Project\n",
    "IMAGE Blur\n",
    "\n",
    "### Aim\n",
    "Fine tune model\n",
    "\n",
    "### Description\n",
    "Try adam optimizer, adaptive learning rate. No improvement\n",
    "\n",
    "### Next Steps\n",
    "Try resnet and unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23th October, 2020\n",
    "---\n",
    "### Project\n",
    "NLP - pipeline\n",
    "\n",
    "### Aim\n",
    "Cover some basics about NLP\n",
    "\n",
    "### Description\n",
    "Go through terms like NER, tokenization, lemmatization etc\n",
    "\n",
    "### Next Steps\n",
    "Apply NER to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28th October, 2020\n",
    "---\n",
    "### Project\n",
    "NLP - pipeline\n",
    "\n",
    "### Aim\n",
    "Attend NLP workshop\n",
    "\n",
    "### Description\n",
    "NLP workshop given by Johan frid. Was not that useful.\n",
    "\n",
    "### Next Steps\n",
    "Apply NER to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "UNET models\n",
    "\n",
    "### Description\n",
    "Look into how unet models work.\n",
    "\n",
    "### Next Steps\n",
    "Unet on LUNARC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Malou's Unet code\n",
    "\n",
    "### Description\n",
    "Look into Malou's code and tried running. Pre-processing worked but training gave dependency issues.\n",
    "\n",
    "### Next Steps\n",
    "Fix issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Malou's Unet code on LUNARC\n",
    "\n",
    "### Description\n",
    "Get LUNARC access. Tried running scripts there but have dependency issues.\n",
    "\n",
    "### Next Steps\n",
    "Fix issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Setup kebnekaise and also use openvpn to access the server\n",
    "\n",
    "### Description\n",
    "Set up Kebnekaise using the following steps:\n",
    "\n",
    "1. Request a user account from SNIC -> HPC2N. The SNIC account was created before.\n",
    "2. Using the login information sent by Kebnekaise personnel (took 2 days), open kebnekaise server using SSH. Since I am using windows, putty was used to run terminal commands. A detailed description is provided in: https://www.hpc2n.umu.se/quickstart\n",
    "3. Once gained access, change the password.\n",
    "4. Now kebnekaise is accessible either through thinLinc or SSH. The server ID is: kebnekaise.hpc2n.umu.se. Note for Lunarc it is aurora.lunarc.lu.se\n",
    "\n",
    "### Results/Conclusion\n",
    "Have access to Kebnekaise now\n",
    "\n",
    "### Next Steps\n",
    "FIX openVPN issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Work on pre-trined models on unet\n",
    "\n",
    "### Description\n",
    "Looked into inception v3 on unet. Aim to implement a simple unet model. Try running scripts on server.\n",
    "\n",
    "### Results/Conclusion\n",
    "Inception v3 appeared tricky to be run on Unet. I couldn't figure out how to use skip connections with pre-trained weights from Inception to Unet\n",
    "\n",
    "### Next Steps\n",
    "Read up on Unet and pre-trained models. Later, implement model with Malou's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 13th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Work on pre-trined models on unet\n",
    "\n",
    "### Description\n",
    "Attempted running Kaggle Carvana colab notebook with VGG16. https://colab.research.google.com/github/MarkDaoust/models/blob/segmentation_blogpost/samples/outreach/blogs/segmentation_blogpost/image_segmentation.ipynb\n",
    "\n",
    "### Results/Conclusion\n",
    "Similar to inception, it was unsuccessfull. The colab notebook gave several errors with the image dataset. Need to build something from scratch\n",
    "\n",
    "### Next Steps\n",
    "Continue Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Adapted Alexandro's tile script to generate 256x256 tiles as inputs for Malou's unet model.\n",
    "\n",
    "### Description\n",
    "Hardcoded the script to create 256x256 tiles. However, I detected several blank tiles when inspecting results.\n",
    "\n",
    "### Next Steps\n",
    "__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15th November 2020\n",
    "---\n",
    "### Project\n",
    "Image to Image translation\n",
    "\n",
    "### Aim\n",
    "Summerize challenge and visualize UNET architecture\n",
    "\n",
    "### Description\n",
    "Assisted the team with several small tasks including writing a script for the visualization of the Unet architecture.\n",
    "Source:https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/\n",
    "Script location: \"shared_data/malou_model5/viz/viz.py\" on Lunarc\n",
    "\n",
    "### Results/Conclusion\n",
    "It was an interesting challenge. However, more work needs to be done to implement pre-trained models on unet.\n",
    "\n",
    "### Next Steps\n",
    "Continue with the project for implementing pre-trained model with Unet (Autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Run Antton's code for NER. Test out the following models:\n",
    "1. NER_biobert-BC5CDRChem_Antton_1, \n",
    "2. NER_biobert-JNLPBA_Antton_1, \n",
    "3. NER_biobert-NCBIdisease_Antton_1\n",
    "\n",
    "### Description\n",
    "Model files were not available. Asked Antton for the files.\n",
    "\n",
    "### Results/Conclusion\n",
    "Waiting for the files\n",
    "\n",
    "### Next Steps\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Use Antton's models to evaluate.\n",
    "\n",
    "### Description\n",
    "Files were received from Antton. His models are located at his personal drive: https://drive.google.com/drive/u/2/folders/1vXBYTh7WmJh8bpmrYTevKLgDuMXemzTZ\n",
    "\n",
    "It was understood that Antton used BIOBERT code to evaluate his models. I will attempt to use the same code for evaluation.\n",
    "\n",
    "### Results/Conclusion\n",
    "Files were shared. However, downloading from Gdrive seemed to give only 1 GB zip files at a time. \n",
    "Trying to understand the evaluation code: \"utils/pubannotationevaluator.py\"\n",
    "\n",
    "### Next Steps\n",
    "Get evaluation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23rd November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Run Antton's Scripts and get results.\n",
    "\n",
    "### Description\n",
    "Was able to successfully run evaluation script, \"utils/use_evaluator.py\". This script is based on the original evaluation code \"utils/pubannotationevaluator.py\".\n",
    "\n",
    "### Results/Conclusions\n",
    "Running the script on \"GOLD william results\", gave a precision value of 26% and recall of 30%. I don't fully understand the script and the terms related to NLP yet.\n",
    "\n",
    "### Next Steps\n",
    "Do a literature review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Improving background in NLP\n",
    "\n",
    "### Description\n",
    "Informed sonja about being unable to understand the script. She shared the following materials to go through.\n",
    "\n",
    "1. Transformers - Attention is all you need: https://arxiv.org/pdf/1706.03762.pdf\n",
    "2. BERT : https://arxiv.org/pdf/1810.04805.pdf\n",
    "3. BioBERT: https://academic.oup.com/bioinformatics/article/36/4/1234/5566506\n",
    "4. Blog Posts: https://jalammar.github.io/illustrated-transformer/\n",
    "5. Blog Posts: http://jalammar.github.io/illustrated-bert/\n",
    "6. CS224 NLP Stanford materials: https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z\n",
    "7. Pubannotation formats: http://www.pubannotation.org/docs/annotation-format/\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "Went through the BERT papers and CS224 lectures briefly. The lectures seemed a bit difficult to understand but the papers were nice.  \n",
    "\n",
    "### Next Steps\n",
    "Continue going through the materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Check if the results in Antton's report matches mine\n",
    "\n",
    "### Description\n",
    "I am expected to run the following three models:\n",
    "1. NCBI Disease\n",
    "2. JNLPBA\n",
    "3. BC5CDR-Chem\n",
    "\n",
    "The firist two folders are located at the \"data/dataset/\" folder in Antton's repo.\n",
    "\n",
    "### Results/Conclusions\n",
    "Following the use_evaluater.py script from Antton, the precision-recall values matched table2 of Antton's preliminary report located in: https://github.com/Aitslab/BioNLP/blob/master/antton/Antton_ProjectReport.docx\n",
    "\n",
    "| Name         | Precision (%) | Recall (%) |\n",
    "|--------------|---------------|------------|\n",
    "| NCBI Disease | 31            | 35         |\n",
    "| JNLPBA       | 0             | 0          |\n",
    "\n",
    "BC5DR-CHEM was not available in the datasets.\n",
    "\n",
    "However, the results were comparable to table 2 of the report and table 1. The evaluation script seems to run on the dataset folder. The models shared by Antton also did not have the right format to run the evaluation script on.\n",
    "\n",
    "\n",
    "### Next Steps\n",
    "Need further understanding of the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30th November 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Meeting and discussion about Antton's models\n",
    "\n",
    "### Description\n",
    "The models were in drive. However while downloading, the models split into multiple files. We needed to contact Antton about the files.\n",
    "\n",
    "### Results/Conclusions\n",
    "On 2nd December it was decided to individually download the files despite the split\n",
    "### Next Steps\n",
    "Continuation with the NLP course (Udemy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st and 2nd December 2020\n",
    "---\n",
    "Setting up the Laptop including Anaconda, Thinlinc and additional programs for servers and setting up CUDA. CUDA setup was not completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd December 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "Download Models run by Antton. Add to Lunarc.\n",
    "\n",
    "### Description\n",
    "The models are 6-8 GB folders each. I have initially tried to download the three models described in Antton's paper.\n",
    "1. NCBI Disease\n",
    "2. JNLPBA\n",
    "3. BC5CDR-Chem\n",
    "\n",
    "### Results/Conclusions\n",
    "#3 has already been added to Lunarc. The rest of the models follow\n",
    "\n",
    "### Next Steps\n",
    "Continuation with the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd December 2020\n",
    "---\n",
    "### Project\n",
    "Citizen Scientist game by Salma\n",
    "\n",
    "### Aim\n",
    "Run the game and annotate 100 images\n",
    "\n",
    "### Description\n",
    "The citizen scientist game developed by Salma has 4 levels with unique tasks. The idea is to annotate 100 images and do a test for the game itself to see that everything is working smoothly.\n",
    "\n",
    "The game was run by using bash and separately using Anaconda. In both instances we received multiple bugs, mostly revolving around local variables (for example \"con\" and \"P1 full filename\") referenced before assignment.\n",
    "\n",
    "### Results/Conclusions\n",
    "The game needs debugging. I am not sure if the errors occur due to LUNARC or the code itself. I have forwarded my findings to Salma.\n",
    "\n",
    "### Next Steps\n",
    "Continue with annotations after receiving the debugged game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd December 2020\n",
    "---\n",
    "### Project\n",
    "NLP - Pipeline\n",
    "\n",
    "### Aim\n",
    "\n",
    "\n",
    "### Description\n",
    "\n",
    "\n",
    "### Results/Conclusions\n",
    "\n",
    "\n",
    "### Next Steps\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
